


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchdata.nodes (beta) &mdash; TorchData 0.10.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Stateful DataLoader" href="torchdata.stateful_dataloader.html" />
    <link rel="prev" title="What is torchdata.nodes (beta)?" href="what_is_torchdata_nodes.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2023">
                  <span class="dropdown-title">Contributor Awards - 2023</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                  <p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/data/versions.html'>0.10.1 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Developer Notes:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="what_is_torchdata_nodes.html">What is <code class="docutils literal notranslate"><span class="pre">torchdata.nodes</span></code> (beta)?</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#"><code class="docutils literal notranslate"><span class="pre">torchdata.nodes</span></code> (beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchdata.stateful_dataloader.html">Stateful DataLoader</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorial and Examples:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started_with_torchdata_nodes.html">Getting Started With <code class="docutils literal notranslate"><span class="pre">torchdata.nodes</span></code> (beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="migrate_to_nodes_from_utils.html">Migrating to <code class="docutils literal notranslate"><span class="pre">torchdata.nodes</span></code> from <code class="docutils literal notranslate"><span class="pre">torch.utils.data</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="stateful_dataloader_tutorial.html">Stateful DataLoader Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchtune">torchtune</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li><code class="docutils literal notranslate"><span class="pre">torchdata.nodes</span></code> (beta)</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/torchdata.nodes.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="admonition attention">
<p class="admonition-title">Attention</p>
<p><strong>June 2024 Status Update: Removing DataPipes and DataLoader V2</strong></p>
<p>We are re-focusing the torchdata repo to be an iterative enhancement of torch.utils.data.DataLoader. We do not plan on
continuing development or maintaining the [<cite>DataPipes</cite>] and [<cite>DataLoaderV2</cite>] solutions, and they will be removed from
the torchdata repo. We’ll also be revisiting the <cite>DataPipes</cite> references in pytorch/pytorch. In release
<cite>torchdata==0.8.0</cite> (July 2024) they will be marked as deprecated, and in 0.10.0 (Late 2024) they will be deleted. Existing
users are advised to pin to <cite>torchdata&lt;=0.9.0</cite> or an older version until they are able to migrate away. Subsequent
releases will not include DataPipes or DataLoaderV2.
Please reach out if you suggestions or comments (please use <a class="reference external" href="https://github.com/pytorch/data/issues/1196">this issue</a> for feedback)</p>
</div>
<section id="module-torchdata.nodes">
<span id="torchdata-nodes-beta"></span><h1><code class="docutils literal notranslate"><span class="pre">torchdata.nodes</span></code> (beta)<a class="headerlink" href="#module-torchdata.nodes" title="Permalink to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.BaseNode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">BaseNode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.BaseNode" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Iterator</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code>]</p>
<p>BaseNodes are the base class for creating composable dataloading DAGs in <code class="docutils literal notranslate"><span class="pre">torchdata.nodes</span></code>.</p>
<p>Most end-users will not iterate over a BaseNode instance directly, but instead
wrap it in a <a class="reference internal" href="#torchdata.nodes.Loader" title="torchdata.nodes.Loader"><code class="xref py py-class docutils literal notranslate"><span class="pre">torchdata.nodes.Loader</span></code></a> which converts the DAG into a more familiar Iterable.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">node</span> <span class="o">=</span> <span class="n">MyBaseNodeImpl</span><span class="p">()</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">Loader</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
<span class="c1"># loader supports state_dict() and load_state_dict()</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
        <span class="o">...</span>

<span class="c1"># or if using node directly:</span>
<span class="n">node</span> <span class="o">=</span> <span class="n">MyBaseNodeImpl</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">node</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
        <span class="o">...</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.BaseNode.get_state">
<span class="sig-name descname"><span class="pre">get_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.BaseNode.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of state_dict(). Should only be called by BaseNode.
:return: Dict[str, Any] - a state dict that may be passed to reset() at some point in the future</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.BaseNode.next">
<span class="sig-name descname"><span class="pre">next</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#torchdata.nodes.BaseNode.next" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of <code class="docutils literal notranslate"><span class="pre">__next</span></code>. Should only be called by BaseNode.
:return: T - the next value in the sequence, or throw StopIteration</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.BaseNode.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.BaseNode.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the iterator to the beginning, or to the state passed in by initial_state.</p>
<p>Reset is a good place to put expensive initialization, as it will be lazily called when next() or state_dict() is called.
Subclasses must call <code class="docutils literal notranslate"><span class="pre">super().reset(initial_state)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>initial_state</strong> – Optional[dict] - a state dict to pass to the node. If None, reset to the beginning.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.BaseNode.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.BaseNode.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a state_dict for this BaseNode.
:return: Dict[str, Any] - a state dict that may be passed to reset() at some point in the future.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.Batcher">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">Batcher</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><span class="pre">BaseNode</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_last</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.Batcher" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseNode</span></code></a>[<code class="xref py py-class docutils literal notranslate"><span class="pre">List</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code>]]</p>
<p>Batcher node batches the data from the source node into batches of size batch_size.
If the source node is exhausted, it will return the batch or raise StopIteration.
If drop_last is True, the last batch will be dropped if it is smaller than batch_size.
If drop_last is False, the last batch will be returned even if it is smaller than batch_size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.BaseNode"><em>BaseNode</em></a><em>[</em><em>T</em><em>]</em>) – The source node to batch the data from.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The size of the batch.</p></li>
<li><p><strong>drop_last</strong> (<em>bool</em>) – Whether to drop the last batch if it is smaller than batch_size. Default is True.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.Batcher.get_state">
<span class="sig-name descname"><span class="pre">get_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.Batcher.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of state_dict(). Should only be called by BaseNode.
:return: Dict[str, Any] - a state dict that may be passed to reset() at some point in the future</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.Batcher.next">
<span class="sig-name descname"><span class="pre">next</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.Batcher.next" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of <code class="docutils literal notranslate"><span class="pre">__next</span></code>. Should only be called by BaseNode.
:return: T - the next value in the sequence, or throw StopIteration</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.Batcher.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.Batcher.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the iterator to the beginning, or to the state passed in by initial_state.</p>
<p>Reset is a good place to put expensive initialization, as it will be lazily called when next() or state_dict() is called.
Subclasses must call <code class="docutils literal notranslate"><span class="pre">super().reset(initial_state)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>initial_state</strong> – Optional[dict] - a state dict to pass to the node. If None, reset to the beginning.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.IterableWrapper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">IterableWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">iterable</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.IterableWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseNode</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code>]</p>
<p>Thin Wrapper that converts any Iterable (including
torch.utils.data.IterableDataset) in to a BaseNode.</p>
<p>If iterable implements the Stateful Protocol, it will be saved and restored with its
state_dict/load_state_dict methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>iterable</strong> (<em>Iterable</em><em>[</em><em>T</em><em>]</em>) – Iterable to convert to BaseNode. IterableWrapper calls iter() on it.</p>
</dd>
<dt class="field-even">Warning<span class="colon">:</span></dt>
<dd class="field-even"><p>Note the distinction between state_dict/load_state_dict defined on Iterable, vs Iterator.
Only the Iterable’s state_dict/load_state_dict are used.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.IterableWrapper.get_state">
<span class="sig-name descname"><span class="pre">get_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.IterableWrapper.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of state_dict(). Should only be called by BaseNode.
:return: Dict[str, Any] - a state dict that may be passed to reset() at some point in the future</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.IterableWrapper.next">
<span class="sig-name descname"><span class="pre">next</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#torchdata.nodes.IterableWrapper.next" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of <code class="docutils literal notranslate"><span class="pre">__next</span></code>. Should only be called by BaseNode.
:return: T - the next value in the sequence, or throw StopIteration</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.IterableWrapper.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.IterableWrapper.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the iterator to the beginning, or to the state passed in by initial_state.</p>
<p>Reset is a good place to put expensive initialization, as it will be lazily called when next() or state_dict() is called.
Subclasses must call <code class="docutils literal notranslate"><span class="pre">super().reset(initial_state)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>initial_state</strong> – Optional[dict] - a state dict to pass to the node. If None, reset to the beginning.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.Loader">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">Loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><span class="pre">BaseNode</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">restart_on_stop_iteration</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.Loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic</span></code>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code>]</p>
<p>Wraps the root BaseNode (an iterator) and provides a stateful iterable interface.</p>
<p>The state of the last-returned iterator is returned by the state_dict() method, and can be
loaded using the load_state_dict() method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.BaseNode"><em>BaseNode</em></a><em>[</em><em>T</em><em>]</em>) – The root node of the data pipeline.</p></li>
<li><p><strong>restart_on_stop_iteration</strong> (<em>bool</em>) – Whether to restart the iterator when it reaches the end. Default is True</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.Loader.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.Loader.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads a state_dict which will be used to initialize the next iter() requested
from this loader.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state_dict</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>Any</em><em>]</em>) – The state_dict to load. Should be generated from a call to state_dict().</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.Loader.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.Loader.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a state_dict which can be passed to load_state_dict() in the future to
resume iteration.</p>
<p>The state_dict will come from the iterator returned by the most recent call to iter().
If no iterator has been created, a new iterator will be created and the state_dict returned from it.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchdata.nodes.MapStyleWrapper">
<span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">MapStyleWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">map_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">K</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sampler</span><span class="p"><span class="pre">[</span></span><span class="pre">K</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><span class="pre">BaseNode</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.MapStyleWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Thin Wrapper that converts any MapDataset in to a torchdata.node
If you want parallelism, copy this and replace Mapper with ParallelMapper.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>map_dataset</strong> (<em>Mapping</em><em>[</em><em>K</em><em>, </em><em>T</em><em>]</em>) – <ul>
<li><p>Apply map_dataset.__getitem__ to the outputs of sampler.</p></li>
</ul>
</p></li>
<li><p><strong>sampler</strong> (<em>Sampler</em><em>[</em><em>K</em><em>]</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torchdata.nodes.Mapper">
<span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">Mapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><span class="pre">BaseNode</span></a><span class="p"><span class="pre">[</span></span><span class="pre">X</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">X</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="#torchdata.nodes.ParallelMapper" title="torchdata.nodes.map.ParallelMapper"><span class="pre">ParallelMapper</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.Mapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a <a class="reference internal" href="#torchdata.nodes.ParallelMapper" title="torchdata.nodes.ParallelMapper"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParallelMapper</span></code></a> node with num_workers=0, which will execute map_fn in the current process/thread.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.BaseNode"><em>BaseNode</em></a><em>[</em><em>X</em><em>]</em>) – The source node to map over.</p></li>
<li><p><strong>map_fn</strong> (<em>Callable</em><em>[</em><em>[</em><em>X</em><em>]</em><em>, </em><em>T</em><em>]</em>) – The function to apply to each item from the source node.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.MultiNodeWeightedSampler">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">MultiNodeWeightedSampler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source_nodes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><span class="pre">BaseNode</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stop_criteria</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'CYCLE_UNTIL_ALL_DATASETS_EXHAUSTED'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">world_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.MultiNodeWeightedSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseNode</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code>]</p>
<p>A node that samples from multiple datasets with weights.</p>
<p>This node expects to take in a dictionary of source nodes, and a dictionary of weights.
The keys of the source nodes and weights must be the same. The weights are used to sample
from the source nodes. We use torch.multinomial to sample from the source nodes, please
refer to <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.multinomial.html">https://pytorch.org/docs/stable/generated/torch.multinomial.html</a> on how to use
weights for sampling. <cite>seed</cite> is used to initialize the random number generator.</p>
<p>The node implements the state using the following keys:
- DATASET_NODE_STATES_KEY: A dictionary of states for each source node.
- DATASETS_EXHAUSTED_KEY: A dictionary of booleans indicating whether each source node is exhausted.
- EPOCH_KEY: An epoch counter used to initialize the random number generator.
- NUM_YIELDED_KEY: The number of items yielded.
- WEIGHTED_SAMPLER_STATE_KEY: The state of the weighted sampler.</p>
<p>We support multiple stopping criteria:
- CYCLE_UNTIL_ALL_DATASETS_EXHAUSTED: Cycle through the source nodes until all datasets are exhausted. This is the default behavior.
- FIRST_DATASET_EXHAUSTED: Stop when the first dataset is exhausted.
- ALL_DATASETS_EXHAUSTED: Stop when all datasets are exhausted.</p>
<p>On complete exhaustion of the source nodes, the node will raise StopIteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source_nodes</strong> (<em>Mapping</em><em>[</em><em>str</em><em>, </em><a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.BaseNode"><em>BaseNode</em></a><em>[</em><em>T</em><em>]</em><em>]</em>) – A dictionary of source nodes.</p></li>
<li><p><strong>weights</strong> (<em>Dict</em><em>[</em><em>str</em><em>, </em><em>float</em><em>]</em>) – A dictionary of weights for each source node.</p></li>
<li><p><strong>stop_criteria</strong> (<em>str</em>) – The stopping criteria. Default is CYCLE_UNTIL_ALL_DATASETS_EXHAUST</p></li>
<li><p><strong>rank</strong> (<em>int</em>) – The rank of the current process. Default is None, in which case the rank
will be obtained from the distributed environment.</p></li>
<li><p><strong>world_size</strong> (<em>int</em>) – The world size of the distributed environment. Default is None, in
which case the world size will be obtained from the distributed environment.</p></li>
<li><p><strong>seed</strong> (<em>int</em>) – The seed for the random number generator. Default is 0.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.MultiNodeWeightedSampler.get_state">
<span class="sig-name descname"><span class="pre">get_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.MultiNodeWeightedSampler.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of state_dict(). Should only be called by BaseNode.
:return: Dict[str, Any] - a state dict that may be passed to reset() at some point in the future</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.MultiNodeWeightedSampler.next">
<span class="sig-name descname"><span class="pre">next</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#torchdata.nodes.MultiNodeWeightedSampler.next" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of <code class="docutils literal notranslate"><span class="pre">__next</span></code>. Should only be called by BaseNode.
:return: T - the next value in the sequence, or throw StopIteration</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.MultiNodeWeightedSampler.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.MultiNodeWeightedSampler.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the iterator to the beginning, or to the state passed in by initial_state.</p>
<p>Reset is a good place to put expensive initialization, as it will be lazily called when next() or state_dict() is called.
Subclasses must call <code class="docutils literal notranslate"><span class="pre">super().reset(initial_state)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>initial_state</strong> – Optional[dict] - a state dict to pass to the node. If None, reset to the beginning.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.ParallelMapper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">ParallelMapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><span class="pre">BaseNode</span></a><span class="p"><span class="pre">[</span></span><span class="pre">X</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">X</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_order</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'thread'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'process'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'thread'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiprocessing_context</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_concurrent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">snapshot_frequency</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.ParallelMapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseNode</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code>]</p>
<p>ParallelMapper executes map_fn in parallel either in num_workers threads or
processes. For processes, multiprocessing_context can be spawn, forkserver, fork,
or None (chooses OS default). At most max_concurrent items will be either processed
or in the iterator’s output queue, to limit CPU and Memory utilization. If None
(default) the value will be 2 * num_workers.</p>
<p>At most one iter() is created from source, and at most one thread will call
next() on it at once.</p>
<p>If in_order is true, the iterator will return items in the order from which they arrive
from source’s iterator, potentially blocking even if other items are available.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.BaseNode"><em>BaseNode</em></a><em>[</em><em>X</em><em>]</em>) – The source node to map over.</p></li>
<li><p><strong>map_fn</strong> (<em>Callable</em><em>[</em><em>[</em><em>X</em><em>]</em><em>, </em><em>T</em><em>]</em>) – The function to apply to each item from the source node.</p></li>
<li><p><strong>num_workers</strong> (<em>int</em>) – The number of workers to use for parallel processing.</p></li>
<li><p><strong>in_order</strong> (<em>bool</em>) – Whether to return items in the order from which they arrive from. Default is True.</p></li>
<li><p><strong>method</strong> (<em>Literal</em><em>[</em><em>&quot;thread&quot;</em><em>, </em><em>&quot;process&quot;</em><em>]</em>) – The method to use for parallel processing. Default is “thread”.</p></li>
<li><p><strong>multiprocessing_context</strong> (<em>Optional</em><em>[</em><em>str</em><em>]</em>) – The multiprocessing context to use for parallel processing. Default is None.</p></li>
<li><p><strong>max_concurrent</strong> (<em>Optional</em><em>[</em><em>int</em><em>]</em>) – The maximum number of items to process at once. Default is None.</p></li>
<li><p><strong>snapshot_frequency</strong> (<em>int</em>) – The frequency at which to snapshot the state of the source node. Default is 1.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.ParallelMapper.get_state">
<span class="sig-name descname"><span class="pre">get_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.ParallelMapper.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of state_dict(). Should only be called by BaseNode.
:return: Dict[str, Any] - a state dict that may be passed to reset() at some point in the future</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.ParallelMapper.next">
<span class="sig-name descname"><span class="pre">next</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.ParallelMapper.next" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of <code class="docutils literal notranslate"><span class="pre">__next</span></code>. Should only be called by BaseNode.
:return: T - the next value in the sequence, or throw StopIteration</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.ParallelMapper.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.ParallelMapper.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the iterator to the beginning, or to the state passed in by initial_state.</p>
<p>Reset is a good place to put expensive initialization, as it will be lazily called when next() or state_dict() is called.
Subclasses must call <code class="docutils literal notranslate"><span class="pre">super().reset(initial_state)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>initial_state</strong> – Optional[dict] - a state dict to pass to the node. If None, reset to the beginning.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.PinMemory">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">PinMemory</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><span class="pre">BaseNode</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pin_memory_device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">snapshot_frequency</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.PinMemory" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseNode</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code>]</p>
<p>Pins the data of the underlying node to a device. This is backed by torch.utils.data._utils.pin_memory._pin_memory_loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.BaseNode"><em>BaseNode</em></a><em>[</em><em>T</em><em>]</em>) – The source node to pin the data from.</p></li>
<li><p><strong>pin_memory_device</strong> (<em>str</em>) – The device to pin the data to. Default is “”.</p></li>
<li><p><strong>snapshot_frequency</strong> (<em>int</em>) – The frequency at which to snapshot the state of the source node. Default is
1, which means that the state of the source node will be snapshotted after every item. If set
to a higher value, the state of the source node will be snapshotted after every snapshot_frequency
items.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.PinMemory.get_state">
<span class="sig-name descname"><span class="pre">get_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.PinMemory.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of state_dict(). Should only be called by BaseNode.
:return: Dict[str, Any] - a state dict that may be passed to reset() at some point in the future</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.PinMemory.next">
<span class="sig-name descname"><span class="pre">next</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.PinMemory.next" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of <code class="docutils literal notranslate"><span class="pre">__next</span></code>. Should only be called by BaseNode.
:return: T - the next value in the sequence, or throw StopIteration</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.PinMemory.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.PinMemory.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the iterator to the beginning, or to the state passed in by initial_state.</p>
<p>Reset is a good place to put expensive initialization, as it will be lazily called when next() or state_dict() is called.
Subclasses must call <code class="docutils literal notranslate"><span class="pre">super().reset(initial_state)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>initial_state</strong> – Optional[dict] - a state dict to pass to the node. If None, reset to the beginning.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.Prefetcher">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">Prefetcher</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><span class="pre">BaseNode</span></a><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefetch_factor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">snapshot_frequency</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.Prefetcher" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseNode</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code>]</p>
<p>Prefetches data from the source node and stores it in a queue.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.BaseNode"><em>BaseNode</em></a><em>[</em><em>T</em><em>]</em>) – The source node to prefetch data from.</p></li>
<li><p><strong>prefetch_factor</strong> (<em>int</em>) – The number of items to prefetch ahead of time.</p></li>
<li><p><strong>snapshot_frequency</strong> (<em>int</em>) – The frequency at which to snapshot the state of the source node. Default is
1, which means that the state of the source node will be snapshotted after every item. If set
to a higher value, the state of the source node will be snapshotted after every snapshot_frequency
items.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.Prefetcher.get_state">
<span class="sig-name descname"><span class="pre">get_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.Prefetcher.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of state_dict(). Should only be called by BaseNode.
:return: Dict[str, Any] - a state dict that may be passed to reset() at some point in the future</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.Prefetcher.next">
<span class="sig-name descname"><span class="pre">next</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.Prefetcher.next" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of <code class="docutils literal notranslate"><span class="pre">__next</span></code>. Should only be called by BaseNode.
:return: T - the next value in the sequence, or throw StopIteration</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.Prefetcher.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.Prefetcher.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the iterator to the beginning, or to the state passed in by initial_state.</p>
<p>Reset is a good place to put expensive initialization, as it will be lazily called when next() or state_dict() is called.
Subclasses must call <code class="docutils literal notranslate"><span class="pre">super().reset(initial_state)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>initial_state</strong> – Optional[dict] - a state dict to pass to the node. If None, reset to the beginning.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.SamplerWrapper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">SamplerWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sampler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Sampler</span><span class="p"><span class="pre">[</span></span><span class="pre">T</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_updater</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.SamplerWrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torchdata.nodes.BaseNode" title="torchdata.nodes.base_node.BaseNode"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseNode</span></code></a>[<code class="xref py py-obj docutils literal notranslate"><span class="pre">T</span></code>]</p>
<p>Convert a sampler into a BaseNode. This is nearly identical to
IterableWrapper except it includes a hook to call set_epoch on the sampler,
if it supports it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sampler</strong> (<em>Sampler</em>) – Sampler to wrap.</p></li>
<li><p><strong>initial_epoch</strong> (<em>int</em>) – initial epoch to set on the sampler</p></li>
<li><p><strong>epoch_updater</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>int</em><em>]</em><em>, </em><em>int</em><em>]</em><em>] </em><em>= None</em>) – callback to update epoch at start of new iteration. It’s called at the beginning of each iterator request, except the first one.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.SamplerWrapper.get_state">
<span class="sig-name descname"><span class="pre">get_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#torchdata.nodes.SamplerWrapper.get_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of state_dict(). Should only be called by BaseNode.
:return: Dict[str, Any] - a state dict that may be passed to reset() at some point in the future</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.SamplerWrapper.next">
<span class="sig-name descname"><span class="pre">next</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T</span></span></span><a class="headerlink" href="#torchdata.nodes.SamplerWrapper.next" title="Permalink to this definition">¶</a></dt>
<dd><p>Subclasses must implement this method, instead of <code class="docutils literal notranslate"><span class="pre">__next</span></code>. Should only be called by BaseNode.
:return: T - the next value in the sequence, or throw StopIteration</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torchdata.nodes.SamplerWrapper.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_state</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.SamplerWrapper.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the iterator to the beginning, or to the state passed in by initial_state.</p>
<p>Reset is a good place to put expensive initialization, as it will be lazily called when next() or state_dict() is called.
Subclasses must call <code class="docutils literal notranslate"><span class="pre">super().reset(initial_state)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>initial_state</strong> – Optional[dict] - a state dict to pass to the node. If None, reset to the beginning.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.Stateful">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">Stateful</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#torchdata.nodes.Stateful" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Protocol</span></code></p>
<p>Protocol for objects implementing both <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> and <code class="docutils literal notranslate"><span class="pre">load_state_dict(state_dict:</span> <span class="pre">Dict[str,</span> <span class="pre">Any])</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torchdata.nodes.StopCriteria">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torchdata.nodes.</span></span><span class="sig-name descname"><span class="pre">StopCriteria</span></span><a class="headerlink" href="#torchdata.nodes.StopCriteria" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Stopping criteria for the dataset samplers.</p>
<ol class="arabic simple">
<li><p>CYCLE_UNTIL_ALL_DATASETS_EXHAUSTED: Stop once the last unseen dataset is exhausted.
All datasets are seen at least once. In certain cases, some datasets may be
seen more than once when there are still non-exhausted datasets.</p></li>
<li><p>ALL_DATASETS_EXHAUSTED: Stop once all have the datasets are exhausted. Each
dataset is seen exactly once. No wraparound or restart will be performed.</p></li>
<li><p>FIRST_DATASET_EXHAUSTED: Stop when the first dataset is exhausted.</p></li>
</ol>
</dd></dl>

</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="torchdata.stateful_dataloader.html" class="btn btn-neutral float-right" title="Stateful DataLoader" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="what_is_torchdata_nodes.html" class="btn btn-neutral" title="What is torchdata.nodes (beta)?" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021 - Present, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#"><code class="docutils literal notranslate"><span class="pre">torchdata.nodes</span></code> (beta)</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>