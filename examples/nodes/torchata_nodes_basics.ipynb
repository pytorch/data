{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0ddf27-b42d-4004-9f0c-4f43e55a245b",
   "metadata": {},
   "source": [
    "### Torchdata.nodes basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff94f5-fc60-4a7e-a3e5-0d7a4bfa2ddd",
   "metadata": {},
   "source": [
    "#### All torchdata.nodes.BaseNode implementations are Iterators, adhering to the following API:\n",
    "```Python\n",
    "class BaseNode(Iterator[T]):\n",
    "    def reset(self, initial_state: Optional[Dict[str, Any]] = None) -> None:\n",
    "        \"\"\"Resets the node to its initial state or a specified state.\"\"\"\n",
    "        ...\n",
    "    def __next__(self) -> T:\n",
    "        \"\"\"Returns the next value in the sequence.\"\"\"\n",
    "        ...\n",
    "    def get_state(self) -> Dict[str, Any]:\n",
    "        \"\"\"Returns a dictionary representing the current state of the node.\"\"\"\n",
    "        ...\n",
    "```\n",
    "#### This standardized interface enables seamless chaining of iterators, allowing for flexible, efficient, and composable data processing pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542e957-f40c-4624-9e3d-b4130d1fd03a",
   "metadata": {},
   "source": [
    "#### Let's see the functionalities of torchdata.nodes through the help of very simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5168248-7c08-419d-a9a5-f831bd7b46e7",
   "metadata": {},
   "source": [
    "#### BaseNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f42819f7-1019-48ca-ad23-00b38c72d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.nodes import IterableWrapper\n",
    "# This Wrapper that converts any Iterable in to a BaseNode.\n",
    "\n",
    "dataset = range(10) # creating a very simple dataset, and then converting it into a BaseNode\n",
    "base_node = IterableWrapper(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb313fe-5cad-4c5f-b7f3-4bd27b0645a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the items in the node\n",
    "for item in base_node:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247845d5-ef4b-4bc3-92c3-93c55972578a",
   "metadata": {},
   "source": [
    "#### Integrating with torch.data Dataloaders and Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14e03a0-29f7-4824-8860-75f1f2a91533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "4\n",
      "7\n",
      "6\n",
      "0\n",
      "3\n",
      "5\n",
      "9\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# We can also use torch.data.utils style dataloaders and samplers, and then wrap them into nodes\n",
    "from torchdata.nodes import MapStyleWrapper\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "sampler = RandomSampler(dataset)\n",
    "node = MapStyleWrapper(map_dataset=dataset, sampler=sampler)\n",
    "\n",
    "for item in node:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f6e1ce-6e33-49cd-b0bb-c49fee0e7cd6",
   "metadata": {},
   "source": [
    "#### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a07a13-5d6f-46d4-b316-102698eb13c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "# We can use the Mapper class, to apply a transformation defined using the `map_fn`\n",
    "from torchdata.nodes import Mapper\n",
    "mapped_dataset = Mapper(base_node, map_fn = lambda x : x**2)\n",
    "for item in mapped_dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0771661d-f0dc-4d35-a5af-abab84d7efd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "# It can also be executed in parallel, using the multi threading/processing approaches, depending the defined `method`\n",
    "from torchdata.nodes import ParallelMapper\n",
    "mapped_dataset = ParallelMapper(base_node, map_fn = lambda x : x**2, num_workers =2, method = \"thread\")\n",
    "for item in mapped_dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b517ebcf-9f92-43bf-b332-3875933ea244",
   "metadata": {},
   "source": [
    "#### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc40c637-90ed-4c09-9961-3b0d488fc6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# A BaseNode can be passed into a Batcher, to get batches of size `batch_size`.\n",
    "# By default, drop_last is True, meaning if the last batch has a size smaller than the `batch_size`, it is not produced.\n",
    "from torchdata.nodes import Batcher\n",
    "batched_dataset = Batcher(base_node, batch_size = 4)\n",
    "for batch in batched_dataset:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "092d8e5b-aeb2-4de1-9b13-8b0dc0af31ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[4, 5, 6, 7]\n",
      "[8, 9]\n"
     ]
    }
   ],
   "source": [
    "# We can make `drop_last = False` to produce the last batch\n",
    "batched_dataset = Batcher(base_node, batch_size = 4, drop_last = False)\n",
    "for batch in batched_dataset:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89e36a9-cc9c-4b55-acba-dbcaf8d53407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch = 0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "On epoch = 1\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "batched_dataset = Batcher(base_node, batch_size = 10)\n",
    "\n",
    "# If we try to use this batcher over multiple epochs, we will need to reset it after every epoch\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"On epoch = {epoch}\")\n",
    "    for batch in batched_dataset:\n",
    "        print(batch)\n",
    "    batched_dataset.reset()\n",
    "    \n",
    "# This is one extra step than traditional dataloader, we can actually wrap the batcher in a Loader to skip that\n",
    "# Let's look at Loader in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2232823-0927-432b-9171-fb2bf38a7205",
   "metadata": {},
   "source": [
    "#### Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f8a1830-49a2-4dfd-b17b-acaca7ac2e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch = 0\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "On epoch = 1\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "from torchdata.nodes import Loader\n",
    "batched_dataset = Batcher(base_node, batch_size = 10)\n",
    "loader = Loader(batched_dataset)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"On epoch = {epoch}\")\n",
    "    for batch in loader:\n",
    "        print(batch)\n",
    "\n",
    "# As you can see, we get a batch in every epoch, without even needing to reset the loader!!\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5384863-fa3e-450e-a8fc-e838e4d2f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchadata nodes are composable, thus, many BaseNodes type nodes can be chained together for desired transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a6291-d688-45eb-bf2e-56153419513e",
   "metadata": {},
   "source": [
    "#### Chaining multiple operations together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bcd30-9a76-4a1e-aa38-d7db8b9a8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomSampler(dataset)\n",
    "node = MapStyleWrapper(map_dataset=dataset, sampler=sampler)\n",
    "mapped_dataset = Mapper(base_node, map_fn = lambda x : x**2)\n",
    "batched_dataset = Batcher(base_node, batch_size = 4, dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f64af-102d-4b24-8327-b47d4d0fc4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88546be-8547-45fd-8620-17aad384ec4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
