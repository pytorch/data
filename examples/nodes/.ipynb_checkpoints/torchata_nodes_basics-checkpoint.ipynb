{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca0ddf27-b42d-4004-9f0c-4f43e55a245b",
   "metadata": {},
   "source": [
    "#### Standard flow control and data processing torchdata.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ff94f5-fc60-4a7e-a3e5-0d7a4bfa2ddd",
   "metadata": {},
   "source": [
    "#### All torchdata.nodes.BaseNode implementations are Iterators, adhering to the following API:\n",
    "```Python\n",
    "class BaseNode(Iterator[T]):\n",
    "    def reset(self, initial_state: Optional[Dict[str, Any]] = None) -> None:\n",
    "        \"\"\"Resets the node to its initial state or a specified state.\"\"\"\n",
    "        ...\n",
    "    def __next__(self) -> T:\n",
    "        \"\"\"Returns the next value in the sequence.\"\"\"\n",
    "        ...\n",
    "    def get_state(self) -> Dict[str, Any]:\n",
    "        \"\"\"Returns a dictionary representing the current state of the node.\"\"\"\n",
    "        ...\n",
    "```\n",
    "#### This standardized interface enables seamless chaining of iterators, allowing for flexible, efficient, and composable data processing pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "632dad1f-fdf0-4e2d-ac92-7cb2c1c99bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f42819f7-1019-48ca-ad23-00b38c72d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.nodes import IterableWrapper\n",
    "#Thin Wrapper that converts any Iterable in to a BaseNode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ba98d5e-bfe7-4b4f-b761-0767273c3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_node = IterableWrapper(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8bb313fe-5cad-4c5f-b7f3-4bd27b0645a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in node:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a14e03a0-29f7-4824-8860-75f1f2a91533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "9\n",
      "5\n",
      "0\n",
      "6\n",
      "7\n",
      "4\n",
      "8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# For people accustomed to torch.data.utils style dataloders and samplers\n",
    "sampler = RandomSampler(dataset)\n",
    "node = MapStyleWrapper(map_dataset=dataset, sampler=sampler)\n",
    "\n",
    "for item in node:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540b85a-7d3d-44b3-ba37-94f1a09d1ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "14c64d71-9fab-44ed-893f-b19de3ffe44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.nodes import Mapper, IterableWrapper, Loader, Batcher, ParallelMapper\n",
    "# Now we can set up some torchdata.nodes to create our pre-proc pipeline\n",
    "from torchdata.nodes import MapStyleWrapper, ParallelMapper, Batcher, PinMemory, Loader\n",
    "from torch.utils.data import default_collate, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328ae33-524e-4da6-bbbf-f3e9fd4658ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ec25081-476e-4945-a590-f7dd289f0804",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1953f770-e0e3-4c2f-9105-2206a16a56bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2768665799.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[84], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    ```Python\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# what's a basenode, print BaseNode API definition\n",
    "# All torchdata.nodes.BaseNode implementations are Iterators.\n",
    "```Python\n",
    "class BaseNode(Iterator[T]):\n",
    "    def reset(self, initial_state: Optional[Dict[str, Any]] = None): ...\n",
    "    def next(self): ...\n",
    "    def get_state(self) -> Dict[str, Any]: ...\n",
    "```\n",
    "# Base node is \n",
    "# All nodes adhere to this API, you can chain iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee200bf-2066-4ab9-87a2-9d894c62e1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552b36b-5e6e-438e-9c27-6664e818dd4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd0370-38bd-4af6-9f65-51b35a0925ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea1d329d-c269-4735-800e-a88ac8c5d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        print(next(node))\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "71a07a13-5d6f-46d4-b316-102698eb13c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "mapped_dataset = Mapper(base_node, map_fn = lambda x : x**2)\n",
    "for item in mapped_dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0771661d-f0dc-4d35-a5af-abab84d7efd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "mapped_dataset = ParallelMapper(base_node, map_fn = lambda x : x**2, num_workers =2, method = \"thread\")\n",
    "for item in mapped_dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "092d8e5b-aeb2-4de1-9b13-8b0dc0af31ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "batched_dataset = Batcher(base_node, batch_size = 4)\n",
    "for batch in batched_dataset:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d12bdaa-e972-4953-8776-791b3e7aeb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[4, 5, 6, 7]\n",
      "[8, 9]\n"
     ]
    }
   ],
   "source": [
    "batched_dataset = Batcher(base_node, batch_size = 4, drop_last = False)\n",
    "for batch in batched_dataset:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a1830-49a2-4dfd-b17b-acaca7ac2e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
