{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5534cad1-3d4b-48c8-899c-135651e143fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import default_collate \n",
    "\n",
    "from torchdata.nodes.adapters import IterableWrapper\n",
    "from torchdata.nodes.batch import Batcher\n",
    "from torchdata.nodes.map import Mapper\n",
    "from torchdata.nodes.loader import Loader\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09803156-6651-4c63-aca2-246076c144e3",
   "metadata": {},
   "source": [
    "### Load IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e285d8-41f7-43ad-98da-02737a862d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "train_dataset = dataset[\"train\"].shuffle(42).select(range(4096))\n",
    "test_dataset = dataset[\"test\"].shuffle(42).select(range(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef11f0c8-b636-47a2-9713-7ad150e9a1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size training = 4096, size test = 1024\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size training = {len(train_dataset[\"text\"])}, size test = {len(test_dataset[\"text\"])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48ab0c-1e16-4b1d-895d-a84bfff9adc6",
   "metadata": {},
   "source": [
    "##### let's look at one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6551b76-b8f1-4156-b5ac-38b31562b0b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\\'s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\\'s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...',\n",
       " 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"text\"][0], train_dataset[\"label\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291509e-ced0-4cfa-a672-d45608f51692",
   "metadata": {},
   "source": [
    "##### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f85e74-0d6f-4336-8b95-f89916161e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "max_len = 512\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b6f4b-7bc2-42e4-8dd1-12a25ee379fb",
   "metadata": {},
   "source": [
    "##### Next we use torchdata.nodes for defining the batcher and transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bafddc5f-cf53-4672-baf9-bc611b70a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_node = IterableWrapper(train_dataset)\n",
    "test_node = IterableWrapper(test_dataset)\n",
    "\n",
    "def map_fn(item, max_len, tokenizer):\n",
    "    text = item[\"text\"]\n",
    "    label = item[\"label\"]\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "        \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "        \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "    }\n",
    "\n",
    "train_mapper = Mapper(train_node,partial(map_fn, max_len=max_len, tokenizer=tokenizer))\n",
    "test_mapper = Mapper(test_node,partial(map_fn, max_len=max_len, tokenizer=tokenizer))\n",
    "\n",
    "#We use Loader so that we do not have to reset the batcher after every epoch\n",
    "train_batcher = Loader(Batcher(train_mapper, batch_size, drop_last=True))\n",
    "test_batcher = Loader(Batcher(test_mapper, 128, drop_last=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c11fc9-c61c-49cd-af4d-3234055609ae",
   "metadata": {},
   "source": [
    "##### Checking how a batch looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0adb6f-9b8f-41e7-af13-1d5b74e54ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  2045,  2003,  ...,     0,     0,     0],\n",
      "        [  101,  2023,  3185,  ...,     0,     0,     0],\n",
      "        [  101,  2577,  1052,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2009,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  2074,  ...,     0,     0,     0],\n",
      "        [  101, 18036,  5886,  ...,  7344,  2474,   102]]) tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]) tensor([1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_batcher:\n",
    "    batch = default_collate(batch)\n",
    "    input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"labels\"]\n",
    "    print(input_ids, attention_mask, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b13174-7e23-46ef-9cb9-d745b1e963e4",
   "metadata": {},
   "source": [
    "##### This LLM has approx 100M params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c606c1ad-74a9-47cb-957b-3060afc59006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 0.109483778 B\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters())/1000000000\n",
    "print(f\"Number of parameters: {num_params} B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c06e5-bd0e-4058-8f35-6450f8451e29",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fcbf9c6-c462-4243-bd96-35a073868048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained on 32 samples.\n",
      "Trained on 64 samples.\n",
      "Trained on 96 samples.\n",
      "Trained on 128 samples.\n",
      "Trained on 160 samples.\n",
      "Trained on 192 samples.\n",
      "Trained on 224 samples.\n",
      "Trained on 256 samples.\n",
      "Trained on 288 samples.\n",
      "Trained on 320 samples.\n",
      "Trained on 352 samples.\n",
      "Trained on 384 samples.\n",
      "Trained on 416 samples.\n",
      "Trained on 448 samples.\n",
      "Trained on 480 samples.\n",
      "Trained on 512 samples.\n",
      "Trained on 544 samples.\n",
      "Trained on 576 samples.\n",
      "Trained on 608 samples.\n",
      "Trained on 640 samples.\n",
      "Trained on 672 samples.\n",
      "Trained on 704 samples.\n",
      "Trained on 736 samples.\n",
      "Trained on 768 samples.\n",
      "Trained on 800 samples.\n",
      "Trained on 832 samples.\n",
      "Trained on 864 samples.\n",
      "Trained on 896 samples.\n",
      "Trained on 928 samples.\n",
      "Trained on 960 samples.\n",
      "Trained on 992 samples.\n",
      "Trained on 1024 samples.\n",
      "Trained on 1056 samples.\n",
      "Trained on 1088 samples.\n",
      "Trained on 1120 samples.\n",
      "Trained on 1152 samples.\n",
      "Trained on 1184 samples.\n",
      "Trained on 1216 samples.\n",
      "Trained on 1248 samples.\n",
      "Trained on 1280 samples.\n",
      "Trained on 1312 samples.\n",
      "Trained on 1344 samples.\n",
      "Trained on 1376 samples.\n",
      "Trained on 1408 samples.\n",
      "Trained on 1440 samples.\n",
      "Trained on 1472 samples.\n",
      "Trained on 1504 samples.\n",
      "Trained on 1536 samples.\n",
      "Trained on 1568 samples.\n",
      "Trained on 1600 samples.\n",
      "Trained on 1632 samples.\n",
      "Trained on 1664 samples.\n",
      "Trained on 1696 samples.\n",
      "Trained on 1728 samples.\n",
      "Trained on 1760 samples.\n",
      "Trained on 1792 samples.\n",
      "Trained on 1824 samples.\n",
      "Trained on 1856 samples.\n",
      "Trained on 1888 samples.\n",
      "Trained on 1920 samples.\n",
      "Trained on 1952 samples.\n",
      "Trained on 1984 samples.\n",
      "Trained on 2016 samples.\n",
      "Trained on 2048 samples.\n",
      "Trained on 2080 samples.\n",
      "Trained on 2112 samples.\n",
      "Trained on 2144 samples.\n",
      "Trained on 2176 samples.\n",
      "Trained on 2208 samples.\n",
      "Trained on 2240 samples.\n",
      "Trained on 2272 samples.\n",
      "Trained on 2304 samples.\n",
      "Trained on 2336 samples.\n",
      "Trained on 2368 samples.\n",
      "Trained on 2400 samples.\n",
      "Trained on 2432 samples.\n",
      "Trained on 2464 samples.\n",
      "Trained on 2496 samples.\n",
      "Trained on 2528 samples.\n",
      "Trained on 2560 samples.\n",
      "Trained on 2592 samples.\n",
      "Trained on 2624 samples.\n",
      "Trained on 2656 samples.\n",
      "Trained on 2688 samples.\n",
      "Trained on 2720 samples.\n",
      "Trained on 2752 samples.\n",
      "Trained on 2784 samples.\n",
      "Trained on 2816 samples.\n",
      "Trained on 2848 samples.\n",
      "Trained on 2880 samples.\n",
      "Trained on 2912 samples.\n",
      "Trained on 2944 samples.\n",
      "Trained on 2976 samples.\n",
      "Trained on 3008 samples.\n",
      "Trained on 3040 samples.\n",
      "Trained on 3072 samples.\n",
      "Trained on 3104 samples.\n",
      "Trained on 3136 samples.\n",
      "Trained on 3168 samples.\n",
      "Trained on 3200 samples.\n",
      "Trained on 3232 samples.\n",
      "Trained on 3264 samples.\n",
      "Trained on 3296 samples.\n",
      "Trained on 3328 samples.\n",
      "Trained on 3360 samples.\n",
      "Trained on 3392 samples.\n",
      "Trained on 3424 samples.\n",
      "Trained on 3456 samples.\n",
      "Trained on 3488 samples.\n",
      "Trained on 3520 samples.\n",
      "Trained on 3552 samples.\n",
      "Trained on 3584 samples.\n",
      "Trained on 3616 samples.\n",
      "Trained on 3648 samples.\n",
      "Trained on 3680 samples.\n",
      "Trained on 3712 samples.\n",
      "Trained on 3744 samples.\n",
      "Trained on 3776 samples.\n",
      "Trained on 3808 samples.\n",
      "Trained on 3840 samples.\n",
      "Trained on 3872 samples.\n",
      "Trained on 3904 samples.\n",
      "Trained on 3936 samples.\n",
      "Trained on 3968 samples.\n",
      "Trained on 4000 samples.\n",
      "Trained on 4032 samples.\n",
      "Trained on 4064 samples.\n",
      "Trained on 4096 samples.\n",
      "Epoch 1, Loss: 0.4513414671101908\n",
      "Tested 128 samples\n",
      "Tested 256 samples\n",
      "Tested 384 samples\n",
      "Tested 512 samples\n",
      "Tested 640 samples\n",
      "Tested 768 samples\n",
      "Tested 896 samples\n",
      "Tested 1024 samples\n",
      "Test Loss: 0.2611520867794752, Accuracy: 0.8916\n"
     ]
    }
   ],
   "source": [
    "# Set device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for num_loop, batch in enumerate(train_batcher):\n",
    "\n",
    "        batch = default_collate(batch)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        print(f\"Trained on {(num_loop+1)*batch_size} samples.\")\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / num_loop}\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        num_samples_tested=0\n",
    "        num_loops=0\n",
    "        for batch in test_batcher:\n",
    "            \n",
    "            batch = default_collate(batch)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.logits, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            num_samples_tested+=128\n",
    "            num_loops+=1\n",
    "            print(f\"Tested {num_samples_tested} samples\")\n",
    "    accuracy = correct / num_samples_tested\n",
    "    print(f\"Test Loss: {test_loss / num_loops}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab50e69-5e3a-46d0-8665-c6b816cefbf2",
   "metadata": {},
   "source": [
    "#### We got an accuracy of around 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2015a656-d648-44bf-ab30-fc34ce628680",
   "metadata": {},
   "source": [
    "##### Let's also test on our custom examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f84489-6c19-41d0-bf24-ba8cbf864d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(review, model, max_len, tokenizer):\n",
    "\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        review,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = encoding[\"input_ids\"].flatten().unsqueeze(0) \n",
    "    attention_mask = encoding[\"attention_mask\"].flatten().unsqueeze(0) \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits)\n",
    "        if predicted_class==0:\n",
    "            print(\"Negative\")\n",
    "        else:\n",
    "            print(\"Positive\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de24f4fa-4050-4ea6-97c5-1634b5321abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"best movie\", model, max_len, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b02965f-469a-4a99-be37-6e9f696111de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"Worst movie ever.\", model, max_len, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7dd9920-ad42-42dd-bac2-9c77674482a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"No other movie is worse than this movie.\", model, max_len, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeed1d96-4a6a-460b-b2eb-0a9871573c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"This is not very good\", model, max_len, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c137160-efcf-4c05-a022-52d72f8e7172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"Will watch again\", model, max_len, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f3e3184-16d2-43c2-afd6-484de3e27601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"I want to watch it again\", model, max_len, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6cc9acf-7cf0-419d-8854-1cc9f93a9879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"I do not want to watch it again\", model, max_len, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b7ade72-fd9e-4a5a-88ed-f2ea5eff577c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"Unwatchable\", model, max_len, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f19f9e-80ae-47d9-a622-6b96161e1bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
