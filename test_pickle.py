# [prefetch is True, 2 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch None results are: total time 153 sec, with 200000 items 1305 per/sec, which is 15% of best. 21813 Mbytes with io speed at 142 MBps
# [prefetch is True, 2 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 67 sec, with 200000 items 2957 per/sec, which is 35% of best. 21813 Mbytes with io speed at 322 MBps
# [prefetch is True, 2 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 200 results are: total time 67 sec, with 200000 items 2955 per/sec, which is 35% of best. 21813 Mbytes with io speed at 322 MBps
# [prefetch is True, 2 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch None results are: total time 166 sec, with 200000 items 1199 per/sec, which is 14% of best. 21813 Mbytes with io speed at 130 MBps
# [prefetch is True, 2 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 72 sec, with 200000 items 2751 per/sec, which is 33% of best. 21813 Mbytes with io speed at 300 MBps
# [prefetch is True, 2 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 200 results are: total time 72 sec, with 200000 items 2754 per/sec, which is 33% of best. 21813 Mbytes with io speed at 300 MBps
# [prefetch is True, 5 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch None results are: total time 279 sec, with 200000 items 714 per/sec, which is 8% of best. 21813 Mbytes with io speed at 77 MBps
# [prefetch is True, 5 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 37 sec, with 200000 items 5326 per/sec, which is 64% of best. 21813 Mbytes with io speed at 580 MBps
# [prefetch is True, 5 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 200 results are: total time 37 sec, with 200000 items 5299 per/sec, which is 63% of best. 21813 Mbytes with io speed at 578 MBps
# [prefetch is True, 5 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch None results are: total time 201 sec, with 200000 items 990 per/sec, which is 11% of best. 21813 Mbytes with io speed at 107 MBps
# [prefetch is True, 5 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 41 sec, with 200000 items 4796 per/sec, which is 57% of best. 21813 Mbytes with io speed at 523 MBps
# [prefetch is True, 5 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 200 results are: total time 41 sec, with 200000 items 4774 per/sec, which is 57% of best. 21813 Mbytes with io speed at 520 MBps
# [prefetch is True, 10 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch None results are: total time 673 sec, with 200000 items 296 per/sec, which is 3% of best. 21813 Mbytes with io speed at 32 MBps
# [prefetch is True, 10 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 40 sec, with 200000 items 4886 per/sec, which is 58% of best. 21813 Mbytes with io speed at 532 MBps
# [prefetch is True, 10 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 200 results are: total time 41 sec, with 200000 items 4852 per/sec, which is 58% of best. 21813 Mbytes with io speed at 529 MBps
# [prefetch is True, 10 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch None results are: total time 564 sec, with 200000 items 354 per/sec, which is 4% of best. 21813 Mbytes with io speed at 38 MBps
# [prefetch is True, 10 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 46 sec, with 200000 items 4329 per/sec, which is 52% of best. 21813 Mbytes with io speed at 472 MBps
# [prefetch is True, 10 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 200 results are: total time 46 sec, with 200000 items 4291 per/sec, which is 51% of best. 21813 Mbytes with io speed at 468 MBps
# [prefetch is True, 15 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch None results are: total time 450 sec, with 200000 items 444 per/sec, which is 5% of best. 21813 Mbytes with io speed at 48 MBps
# [prefetch is True, 15 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 43 sec, with 200000 items 4588 per/sec, which is 55% of best. 21813 Mbytes with io speed at 500 MBps
# [prefetch is True, 15 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 200 results are: total time 43 sec, with 200000 items 4552 per/sec, which is 54% of best. 21813 Mbytes with io speed at 496 MBps


# Proto V1

# [prefetch is True, 2 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch None results are: total time 154 sec, with 200000 items 1295 per/sec, which is 19% of best. 21813 Mbytes with io speed at 141 MBps
# [prefetch is True, 2 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch 50 results are: total time 67 sec, with 200000 items 2964 per/sec, which is 45% of best. 21813 Mbytes with io speed at 323 MBps
# [prefetch is True, 2 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch 200 results are: total time 67 sec, with 200000 items 2964 per/sec, which is 45% of best. 21813 Mbytes with io speed at 323 MBps
# [prefetch is True, 2 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch None results are: total time 167 sec, with 200000 items 1192 per/sec, which is 18% of best. 21813 Mbytes with io speed at 130 MBps
# [prefetch is True, 2 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch 50 results are: total time 72 sec, with 200000 items 2741 per/sec, which is 41% of best. 21813 Mbytes with io speed at 298 MBps
# [prefetch is True, 2 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch 200 results are: total time 72 sec, with 200000 items 2753 per/sec, which is 42% of best. 21813 Mbytes with io speed at 300 MBps
# [prefetch is True, 5 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch None results are: total time 156 sec, with 200000 items 1275 per/sec, which is 19% of best. 21813 Mbytes with io speed at 139 MBps
# [prefetch is True, 5 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch 50 results are: total time 38 sec, with 200000 items 5136 per/sec, which is 78% of best. 21813 Mbytes with io speed at 560 MBps
# [prefetch is True, 5 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch 200 results are: total time 39 sec, with 200000 items 5029 per/sec, which is 76% of best. 21813 Mbytes with io speed at 548 MBps
# [prefetch is True, 5 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch None results are: total time 169 sec, with 200000 items 1180 per/sec, which is 18% of best. 21813 Mbytes with io speed at 128 MBps
# [prefetch is True, 5 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch 50 results are: total time 42 sec, with 200000 items 4663 per/sec, which is 71% of best. 21813 Mbytes with io speed at 508 MBps
# [prefetch is True, 5 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch 200 results are: total time 43 sec, with 200000 items 4576 per/sec, which is 70% of best. 21813 Mbytes with io speed at 499 MBps

# [prefetch is True, 10 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch None results are: total time 157 sec, with 200000 items 1269 per/sec, which is 19% of best. 21813 Mbytes with io speed at 138 MBps
# [prefetch is True, 10 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch 50 results are: total time 41 sec, with 200000 items 4765 per/sec, which is 72% of best. 21813 Mbytes with io speed at 519 MBps
# [prefetch is True, 10 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch 200 results are: total time 42 sec, with 200000 items 4724 per/sec, which is 72% of best. 21813 Mbytes with io speed at 515 MBps
# [prefetch is True, 10 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch None results are: total time 171 sec, with 200000 items 1165 per/sec, which is 17% of best. 21813 Mbytes with io speed at 127 MBps
# [prefetch is True, 10 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch 50 results are: total time 47 sec, with 200000 items 4174 per/sec, which is 63% of best. 21813 Mbytes with io speed at 455 MBps
# [prefetch is True, 10 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch 200 results are: total time 48 sec, with 200000 items 4143 per/sec, which is 63% of best. 21813 Mbytes with io speed at 451 MBps
# [prefetch is True, 15 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch None results are: total time 158 sec, with 200000 items 1261 per/sec, which is 19% of best. 21813 Mbytes with io speed at 137 MBps
# [prefetch is True, 15 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch 50 results are: total time 44 sec, with 200000 items 4457 per/sec, which is 68% of best. 21813 Mbytes with io speed at 486 MBps
# [prefetch is True, 15 workers] pickle_dp and Prototype2MultiProcessingReadingService with prefetch 200 results are: total time 44 sec, with 200000 items 4455 per/sec, which is 68% of best. 21813 Mbytes with io speed at 485 MBps
# [prefetch is True, 15 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch None results are: total time 171 sec, with 200000 items 1165 per/sec, which is 17% of best. 21813 Mbytes with io speed at 127 MBps
# [prefetch is True, 15 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch 50 results are: total time 51 sec, with 200000 items 3887 per/sec, which is 59% of best. 21813 Mbytes with io speed at 424 MBps
# [prefetch is True, 15 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch 200 results are: total time 51 sec, with 200000 items 3866 per/sec, which is 59% of best. 21813 Mbytes with io speed at 421 MBps
# [prefetch is True, 2 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch None results are: total time 153 sec, with 200000 items 1304 per/sec, which is 19% of best. 21813 Mbytes with io speed at 142 MBps
# [prefetch is True, 2 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 67 sec, with 200000 items 2965 per/sec, which is 45% of best. 21813 Mbytes with io speed at 323 MBps
# [prefetch is True, 2 workers] pickle_dp and PrototypeMultiProcessingReadingService with prefetch 200 results are: total time 67 sec, with 200000 items 2973 per/sec, which is 45% of best. 21813 Mbytes with io speed at 324 MBps


# Aka old dataloader
# [2 workers] pickle_dp and MultiProcessingReadingService with prefetch None results are: total time 81 sec, with 200000 items 2445 per/sec, which is 50% of best. 21813 Mbytes with io speed at 266 MBps
# [2 workers] tar_dp and MultiProcessingReadingService with prefetch None results are: total time 74 sec, with 200000 items 2691 per/sec, which is 55% of best. 21813 Mbytes with io speed at 293 MBps
# [2 workers] pickle_dp and MultiProcessingReadingService with prefetch 50 results are: total time 68 sec, with 200000 items 2921 per/sec, which is 59% of best. 21813 Mbytes with io speed at 318 MBps
# [2 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 75 sec, with 200000 items 2650 per/sec, which is 54% of best. 21813 Mbytes with io speed at 289 MBps
# [5 workers] pickle_dp and MultiProcessingReadingService with prefetch None results are: total time 32 sec, with 200000 items 6085 per/sec, which is 124% of best. 21813 Mbytes with io speed at 663 MBps
# [5 workers] tar_dp and MultiProcessingReadingService with prefetch None results are: total time 30 sec, with 200000 items 6533 per/sec, which is 133% of best. 21813 Mbytes with io speed at 712 MBps
# [5 workers] pickle_dp and MultiProcessingReadingService with prefetch 50 results are: total time 31 sec, with 200000 items 6292 per/sec, which is 128% of best. 21813 Mbytes with io speed at 686 MBps
# [5 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 32 sec, with 200000 items 6097 per/sec, which is 124% of best. 21813 Mbytes with io speed at 665 MBps
# [10 workers] pickle_dp and MultiProcessingReadingService with prefetch None results are: total time 33 sec, with 200000 items 5957 per/sec, which is 121% of best. 21813 Mbytes with io speed at 649 MBps
# [10 workers] tar_dp and MultiProcessingReadingService with prefetch None results are: total time 32 sec, with 200000 items 6226 per/sec, which is 127% of best. 21813 Mbytes with io speed at 679 MBps
# [10 workers] pickle_dp and MultiProcessingReadingService with prefetch 50 results are: total time 33 sec, with 200000 items 5885 per/sec, which is 120% of best. 21813 Mbytes with io speed at 641 MBps
# [10 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 34 sec, with 200000 items 5862 per/sec, which is 119% of best. 21813 Mbytes with io speed at 639 MBps
# [15 workers] pickle_dp and MultiProcessingReadingService with prefetch None results are: total time 33 sec, with 200000 items 5997 per/sec, which is 122% of best. 21813 Mbytes with io speed at 654 MBps
# [15 workers] tar_dp and MultiProcessingReadingService with prefetch None results are: total time 32 sec, with 200000 items 6184 per/sec, which is 126% of best. 21813 Mbytes with io speed at 674 MBps
# [15 workers] pickle_dp and MultiProcessingReadingService with prefetch 50 results are: total time 35 sec, with 200000 items 5652 per/sec, which is 115% of best. 21813 Mbytes with io speed at 616 MBps
# [15 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 35 sec, with 200000 items 5625 per/sec, which is 115% of best. 21813 Mbytes with io speed at 613 MBps

# Notes increase workers count to make it io bound instead of cpu bound

# Note: taka a look why fan out process take 30% cpu, and more with oncreased workers count?


# Reading with double compute complexity and twice smaller dataset 

# [prefetch is True, 0 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 129 sec, with 100000 items 774 per/sec, which is 11% of best. 10906 Mbytes with io speed at 84 MBps, time to first 10 is 0.01625347137451172
# [0 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 131 sec, with 100000 items 759 per/sec, which is 11% of best. 10906 Mbytes with io speed at 82 MBps, time to first 10 is 0.03664374351501465
# [prefetch is True, 1 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 129 sec, with 100000 items 770 per/sec, which is 11% of best. 10906 Mbytes with io speed at 84 MBps, time to first 10 is 0.023337841033935547
# [1 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 130 sec, with 100000 items 766 per/sec, which is 11% of best. 10906 Mbytes with io speed at 83 MBps, time to first 10 is 0.02572011947631836
# [prefetch is True, 2 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 65 sec, with 100000 items 1535 per/sec, which is 23% of best. 10906 Mbytes with io speed at 167 MBps, time to first 10 is 0.045964956283569336
# [2 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 65 sec, with 100000 items 1523 per/sec, which is 23% of best. 10906 Mbytes with io speed at 166 MBps, time to first 10 is 0.04864668846130371
# [prefetch is True, 3 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 44 sec, with 100000 items 2259 per/sec, which is 34% of best. 10906 Mbytes with io speed at 246 MBps, time to first 10 is 0.06968808174133301
# [3 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 44 sec, with 100000 items 2226 per/sec, which is 34% of best. 10906 Mbytes with io speed at 242 MBps, time to first 10 is 0.050726890563964844
# [prefetch is True, 4 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 32 sec, with 100000 items 3046 per/sec, which is 46% of best. 10906 Mbytes with io speed at 332 MBps, time to first 10 is 0.06954717636108398
# [4 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 33 sec, with 100000 items 3003 per/sec, which is 45% of best. 10906 Mbytes with io speed at 327 MBps, time to first 10 is 0.05628490447998047
# [prefetch is True, 5 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 26 sec, with 100000 items 3798 per/sec, which is 58% of best. 10906 Mbytes with io speed at 414 MBps, time to first 10 is 0.08799314498901367
# [5 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 27 sec, with 100000 items 3699 per/sec, which is 56% of best. 10906 Mbytes with io speed at 403 MBps, time to first 10 is 0.06288027763366699
# [prefetch is True, 6 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 22 sec, with 100000 items 4436 per/sec, which is 67% of best. 10906 Mbytes with io speed at 483 MBps, time to first 10 is 0.09123086929321289
# [6 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 23 sec, with 100000 items 4341 per/sec, which is 66% of best. 10906 Mbytes with io speed at 473 MBps, time to first 10 is 0.07623052597045898
# [prefetch is True, 7 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 23 sec, with 100000 items 4245 per/sec, which is 64% of best. 10906 Mbytes with io speed at 463 MBps, time to first 10 is 0.1040036678314209
# [7 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 20 sec, with 100000 items 4936 per/sec, which is 75% of best. 10906 Mbytes with io speed at 538 MBps, time to first 10 is 0.08109474182128906
# [prefetch is True, 8 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 23 sec, with 100000 items 4255 per/sec, which is 65% of best. 10906 Mbytes with io speed at 464 MBps, time to first 10 is 0.10865163803100586
# [8 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 17 sec, with 100000 items 5586 per/sec, which is 85% of best. 10906 Mbytes with io speed at 609 MBps, time to first 10 is 0.08365964889526367
# [prefetch is True, 9 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 24 sec, with 100000 items 4058 per/sec, which is 62% of best. 10906 Mbytes with io speed at 442 MBps, time to first 10 is 0.12054967880249023
# [9 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 18 sec, with 100000 items 5471 per/sec, which is 83% of best. 10906 Mbytes with io speed at 596 MBps, time to first 10 is 0.09275007247924805
# [prefetch is True, 10 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 24 sec, with 100000 items 4063 per/sec, which is 62% of best. 10906 Mbytes with io speed at 443 MBps, time to first 10 is 0.14798378944396973
# [10 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 17 sec, with 100000 items 5784 per/sec, which is 88% of best. 10906 Mbytes with io speed at 630 MBps, time to first 10 is 0.10210490226745605
# [prefetch is True, 11 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 25 sec, with 100000 items 3987 per/sec, which is 61% of best. 10906 Mbytes with io speed at 434 MBps, time to first 10 is 0.14172911643981934
# [11 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 18 sec, with 100000 items 5302 per/sec, which is 81% of best. 10906 Mbytes with io speed at 578 MBps, time to first 10 is 0.11306095123291016
# [prefetch is True, 12 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 25 sec, with 100000 items 3986 per/sec, which is 61% of best. 10906 Mbytes with io speed at 434 MBps, time to first 10 is 0.16420745849609375
# [12 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 18 sec, with 100000 items 5382 per/sec, which is 82% of best. 10906 Mbytes with io speed at 587 MBps, time to first 10 is 0.10805082321166992
# [prefetch is True, 13 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 25 sec, with 100000 items 3962 per/sec, which is 60% of best. 10906 Mbytes with io speed at 432 MBps, time to first 10 is 0.170487642288208
# [13 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 18 sec, with 100000 items 5496 per/sec, which is 84% of best. 10906 Mbytes with io speed at 599 MBps, time to first 10 is 0.13512849807739258
# [prefetch is True, 14 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 26 sec, with 100000 items 3774 per/sec, which is 57% of best. 10906 Mbytes with io speed at 411 MBps, time to first 10 is 0.18923640251159668
# [14 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 19 sec, with 100000 items 5139 per/sec, which is 78% of best. 10906 Mbytes with io speed at 560 MBps, time to first 10 is 0.1720139980316162
# [prefetch is True, 5 workers] tar_dp and PrototypeMultiProcessingReadingService with prefetch 50 results are: total time 26 sec, with 100000 items 3799 per/sec, which is 58% of best. 10906 Mbytes with io speed at 414 MBps, time to first 10 is 0.08540225028991699
# [prefetch is True, 5 workers] tar_dp and Prototype2MultiProcessingReadingService with prefetch 50 results are: total time 26 sec, with 100000 items 3781 per/sec, which is 57% of best. 10906 Mbytes with io speed at 412 MBps, time to first 10 is 0.09877181053161621
# [5 workers] tar_dp and MultiProcessingReadingService with prefetch 50 results are: total time 26 sec, with 100000 items 3749 per/sec, which is 57% of best. 10906 Mbytes with io speed at 408 MBps, time to first 10 is 0.06754255294799805

import multiprocessing as mp
import os

# from torchdata.dataloader2 import communication
import threading
import hashlib
import time
import pickle
from torchdata.dataloader2 import (
    communication,
    DataLoader2,
    MultiProcessingReadingService,
    Prototype2MultiProcessingReadingService,
    PrototypeMultiProcessingReadingService,
)
from torchdata.datapipes.iter import IterableWrapper, IterDataPipe


def inc(x):
    return x + 1


def is_odd(x):
    return bool(x % 2)


class PrefetchData:
    def __init__(self, source_datapipe, prefetch):
        self.run_prefetcher = True
        self.prefetch_buffer = []
        self.prefetch = prefetch
        self.source_datapipe = source_datapipe


class PrefetcherIterDataPipe(IterDataPipe):
    def __init__(self, source_datapipe, prefetch=10):
        self.source_datapipe = source_datapipe
        self.prefetch = prefetch
        self.thread = None

    @staticmethod
    def thread_worker(prefetch_data):
        # print(os.getpid(), "!!!!!!!! thread starting")
        # time.sleep(10)
        # print('now creating iterator')
        itr = iter(prefetch_data.source_datapipe)
        # print(os.getpid(), "iterator done")
        stop_iteration = False
        while prefetch_data.run_prefetcher:
            if len(prefetch_data.prefetch_buffer) < prefetch_data.prefetch and not stop_iteration:
                try:
                    # print(os.getpid(), "thread getting item")
                    # if prefetch_data.run_prefetcher:
                    item = next(itr)
                    # print(os.getpid(), "thread getting item complete")
                    prefetch_data.prefetch_buffer.append(item)
                    # print(os.getpid(), "item received and store in buffer of ", len(prefetch_data.prefetch_buffer))
                except (
                    RuntimeError,
                    StopIteration,
                ):  # TODO(VitalyFedyunin): Instead of general exception catch invalid iterator here
                    stop_iteration = True
                except communication.iter.InvalidStateResetRequired:
                    stop_iteration = True
                except communication.iter.TerminateRequired:
                    prefetch_data.run_prefetcher = False
            if stop_iteration and len(prefetch_data.prefetch_buffer) == 0:
                # print(os.getpid(), "all items done, leaving thread myself")
                prefetch_data.run_prefetcher = False
            # print(os.getpid(),'thread wait with full buffer')
            time.sleep(0.00001)
        # print(os.getpid(), "!!!!!!!!  exiting prefetch thread")

    def __iter__(self):
        self.reset()
        # self.run_prefetcher = True
        # print(os.getpid(), ">>>>>>>> start thread")
        prefetch_data = PrefetchData(self.source_datapipe, self.prefetch)
        self.prefetch_data = prefetch_data
        self.thread = threading.Thread(target=PrefetcherIterDataPipe.thread_worker, args=(prefetch_data,), daemon=True)
        self.thread.start()
        i = 0
        while prefetch_data.run_prefetcher:
            if len(prefetch_data.prefetch_buffer) > 0:
                # print(os.getpid(), "main loop returns item from buffer")
                yield prefetch_data.prefetch_buffer[0]
                prefetch_data.prefetch_buffer = prefetch_data.prefetch_buffer[1:]
            else:
                # print('waiting element {}-th time'.format(i))
                # i += 1
                time.sleep(0.00001)
        prefetch_data.run_prefetcher = False
        self.thread.join()
        self.thread = None

    def reset(self):
        # print(os.getpid(), "resetting datapipe")
        if "terminate" in os.environ:
            raise Exception(os.getpid(), "who did it?")
        if self.thread is not None:
            self.prefetch_data.run_prefetcher = False
            self.thread.join()
        # print(os.getpid(), "Reset complete")

    def reset_iterator(self):
        # print(os.getpid(), "reset_iterator called on prefetcher")
        self.reset()


class RangeDebug:
    def __init__(self, x):
        self.x = x

    def __iter__(self):
        for i in range(self.x):
            print(os.getpid(), f">>>>>>>> returning {i}")
            yield i


def post_adapter_fn(dp):
    return PrefetcherIterDataPipe(dp, 10)


def map_read(x):
    data = x[1].read()
    x[1].close()
    return x[0], data

def map_calculate_md5(x):
    long_str = ''
    # for i in range(4):
    for i in range(8):
        long_str += str(hashlib.md5(x[1]).hexdigest())
    #  result = hashlib.md5(x[1]).hexdigest()
    result = hashlib.md5(long_str.encode()).hexdigest()
    size = len(x[1])
    return (x[0], str(result), size)


class UnpickleDP(IterDataPipe):
    def __init__(self, source_datapipe):
        self.source_datapipe = source_datapipe
        # self.prefetch = prefetch
        # self.thread = None
    
    def __iter__(self):
        for filename in self.source_datapipe:
            with open(filename, 'rb') as handle:
                b = pickle.load(handle)
            yield b


# Create pickle files
def main_():
    dp = IterableWrapper(['tar_images.tar']).open_files(mode = 'b').load_from_tar()
    all = list(dp)
    # print(all)
    all_data = []
    for path, stream in all:
        data = stream.read()
        # print(len(data))
        all_data.append((path, data))
    # i = pickle.dumps(all_data)

    with open('images.pickle', 'wb') as handle:
        pickle.dump(all_data, handle, protocol=pickle.HIGHEST_PROTOCOL)

    # print(len(i) / 1024 / 1024)

def noop(x):
    return x

ITEMS_NUM = 100
PREFETCH_ITEMS = 200

def tar_dp():
    tar_files = [ f"tar_files/tar_images{i}.tar" for i in range(ITEMS_NUM)]
    dp = IterableWrapper(tar_files).shuffle().sharding_filter()
    dp = dp.open_files(mode = 'b').load_from_tar(mode = 'r:')
    dp = dp.map(map_read)
    dp = dp.map(map_calculate_md5)
    # dp = PrefetcherIterDataPipe(dp, PREFETCH_ITEMS)
    return dp

def pickle_dp():
    pickle_files = [ f"pickle_files/images{i}.pickle" for i in range(ITEMS_NUM)]
    dp = IterableWrapper(pickle_files).shuffle().sharding_filter()
    dp = UnpickleDP(dp).flatmap(noop)
    dp = dp.map(map_calculate_md5)
    # dp = PrefetcherIterDataPipe(dp, PREFETCH_ITEMS)
    return dp


def check_and_output_speed(prefix, function, rs, prefetch = None):
    best = 6533 # calculate md5 4-times
    # /dev/nvme1n1p1:
    # Timing cached reads:       33676 MB in  2.00 seconds = 16867.31 MB/sec
    # Timing buffered disk reads: 2020 MB in  3.00 seconds = 673.32 MB/sec
    # [5 workers] tar_dp and MultiProcessingReadingService with prefetch None results are: total time 30 sec, with 200000 items 6533 per/sec, which is 133% of best. 21813 Mbytes with io speed at 712 MBps
    dp = function()

    if prefetch is not None:
        dp = PrefetcherIterDataPipe(dp, prefetch)
    

    if rs is not None:
        rs_type = rs.__class__.__name__
        dl = DataLoader2(dp, reading_service=rs)
    else:
        dl = dp
        rs_type = '[Pure DataPipe]'

    start = time.time()
    report = start
    items_len = 0
    total_size = 0
    time_to_first = None
    # print('starting iterations')
    for _name, _md5, size in dl:
        if items_len > 10 and time_to_first is None:
            time_to_first = time.time() - start
        total_size += size
        # print(total_size)
        items_len += 1
        if time.time() - report > 60:
            # print(f"{items_len} items processed so far {total_size} bytes")
            report = time.time()

    total = time.time() - start
    speed = int(items_len / total)
    speed_pct = int(( speed / best ) * 100 )
    function_name = function.__name__
    
    io_speed = int(total_size / total / 1024 / 1024)
    total_size = int(total_size / 1024 / 1024)
    total = int(total)
    # print(f'{prefix} {function_name} and {rs_type} with prefetch {prefetch} results are: total time {total} sec, with {items_len} items {speed} per/sec, which is {speed_pct}% of best. {total_size} Mbytes with io speed at {io_speed} MBps')
    print(f'{prefix} {function_name} and {rs_type} with prefetch {prefetch} results are: total time {total} sec, with {items_len} items at {speed} per/sec. {total_size} Mbytes with io speed at {io_speed} MBps')
    

def main():

    for workers in range(8, 20):

        rs = PrototypeMultiProcessingReadingService(num_workers=workers, post_adapter_fn=post_adapter_fn)
        check_and_output_speed(f"[prefetch is True, {workers} workers]", tar_dp, rs, prefetch = 50) 

        rs = MultiProcessingReadingService(num_workers=workers)
        check_and_output_speed(f"[{workers} workers]", tar_dp, rs, prefetch = 50)

    # rs = PrototypeMultiProcessingReadingService(num_workers=5, post_adapter_fn=post_adapter_fn)
    # check_and_output_speed(f"[prefetch is True, 5 workers]", tar_dp, rs, prefetch = 50)

    # rs = Prototype2MultiProcessingReadingService(num_workers=5, post_adapter_fn=post_adapter_fn)
    # check_and_output_speed(f"[prefetch is True, 5 workers]", tar_dp, rs, prefetch = 50)

    # rs = MultiProcessingReadingService(num_workers=5)
    # check_and_output_speed(f"[5 workers]", tar_dp, rs, prefetch = 50)   

    # rs = PrototypeMultiProcessingReadingService(num_workers=1, post_adapter_fn=post_adapter_fn)
    # check_and_output_speed(f"[prefetch is True, 1 worker]", tar_dp, rs, prefetch = 50) 

    # rs = MultiProcessingReadingService(num_workers=1)
    # check_and_output_speed(f"[1 worker]", tar_dp, rs, prefetch = 50)

    # check_and_output_speed(f"[1 inprocess]", tar_dp, None, prefetch = 50)

    # check_and_output_speed(f"[1 inprocess]", tar_dp, None, prefetch = None)

def main_full():

    for proto in [Prototype2MultiProcessingReadingService, PrototypeMultiProcessingReadingService]:
    # for proto in [Prototype2MultiProcessingReadingService]:
        for workers in [2, 5,10,15]:
            for use_post_adapter_fn in [post_adapter_fn]: # Not working with None(?)
                for function in [pickle_dp, tar_dp]:
                    for use_prefetch in [None, 50, 200]:
                        rs = proto(num_workers=workers, post_adapter_fn = use_post_adapter_fn)
                        use_global_prefetch = use_post_adapter_fn is not None
                        check_and_output_speed(f"[prefetch is {use_global_prefetch}, {workers} workers]", function, rs, prefetch = use_prefetch)

    for workers in [2, 5,10,15]:
        for use_prefetch in [None, 50]:
            for function in [pickle_dp, tar_dp]:
                rs = MultiProcessingReadingService(num_workers=workers)
                check_and_output_speed(f"[{workers} workers]", function, rs, prefetch = use_prefetch)    






def slow_map(x):
    return x


def main_test():
    items = 1000
    dp = IterableWrapper(RangeDebug(items)).map(slow_map).filter(is_odd).sharding_filter()
    dp = PrefetcherIterDataPipe(dp, 20)
    dp = dp.map(slow_map)
    for i in iter(dp):
        print(i)


def main_mp_test():
    items = 1000
    datapipe = IterableWrapper(RangeDebug(items))

    ctx = mp.get_context("fork")
    num_workers = 2
    forked_dps = datapipe.fork(num_workers)

    sharded_forked_dps = []
    # Manually add sharding filters (per forked pipe), and apply sharding
    for pipe_id, pipe in enumerate(forked_dps):
        sharded_dp = pipe.sharding_filter()
        sharded_dp.apply_sharding(num_workers, pipe_id)
        sharded_forked_dps.append(sharded_dp)
    call_inside_process = None  # functools.partial(self.init_datapipe_process, 1, 0)
    process, pipes_and_queues = communication.eventloop.SpawnProcessForMultipleDataPipelines(
        ctx, sharded_forked_dps, call_inside_process
    )
    process.start()

    processes = []
    datapipes = []

    # Take care about termination of the separate process
    for _, req_queue, res_queue in pipes_and_queues:
        dp = communication.iter.QueueWrapper(
            communication.protocol.IterDataPipeQueueProtocolClient(req_queue, res_queue)
        )
        datapipes.append(dp)
        processes.append((process, req_queue, res_queue))

    # print(datapipes)

    dp0, dp1 = datapipes
    print(os.getpid(), "creating iterator 0")
    it0 = iter(dp0)
    print(os.getpid(), "creating iterator 1")
    it1 = iter(dp1)
    print(os.getpid(), "next(it0)")
    item0 = next(it0)
    print(item0)
    item1 = next(it1)
    print(item1)
    item0 = next(it0)
    item0 = next(it0)
    item1 = next(it1)
    print(os.getpid(), "resetting it1")
    it1 = iter(dp1)
    print(os.getpid(), "getting from it1")
    item1 = next(it1)
    print(os.getpid(), "getting from it0")
    try:
        item0 = next(it0)
    except communication.iter.InvalidStateResetRequired:
        print(os.getpid(), "invalid iterator confirmed")
    print(os.getpid(), "creating new iterator")
    it0 = iter(dp0)
    print(os.getpid(), "getting new item")
    item0 = next(it0)

    for process, req_queue, res_queue in processes:
        req_queue.put(communication.messages.TerminateRequest())

    process.join()


main()
