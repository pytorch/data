# Copyright (c) Facebook, Inc. and its affiliates.
import warnings

from typing import Callable, Dict, Optional

from torch.utils.data import IterDataPipe, MapDataPipe
from torch.utils.data.datapipes.utils.common import check_lambda_fn, DILL_AVAILABLE

if DILL_AVAILABLE:
    import dill

    dill.extend(use_dill=False)


class IterToMapConverterMapDataPipe(MapDataPipe):
    r"""
    Lazily load data from IterDataPipe to construct a dictionary with the
    key-value pair generated by ``key_fn`` and ``value_fn``.

    Args:
        datapipe: Source IterDataPipe
        key_fn: Function being applied over each data to generate key
        value_fn: Function being applied over each data to generate value
    """
    datapipe: IterDataPipe
    key_fn: Callable
    value_fn: Optional[Callable]
    _map: Optional[Dict]
    _length: int

    def __init__(self, datapipe: IterDataPipe, key_fn: Callable, value_fn: Optional[Callable] = None):
        if not isinstance(datapipe, IterDataPipe):
            raise TypeError(f"IterToMapConverter can only apply on IterDataPipe, but found {type(datapipe)}")
        self.datapipe = datapipe
        check_lambda_fn(key_fn)
        self.key_fn = key_fn  # type: ignore[assignment]
        check_lambda_fn(value_fn)
        self.value_fn = value_fn
        self._map = None
        self._length = -1

    def _load_map(self):
        self._map = {}
        for d in self.datapipe:
            k = self.key_fn(d)
            if k in self._map:
                raise KeyError(f"Found duplicate key {k}. Please check your key_fn or filter out duplicate data.")
            if self.value_fn is None:
                self._map[k] = d
            else:
                self._map[k] = self.value_fn(d)

    def __getitem__(self, index):
        if self._map is None:
            self._load_map()
        return self._map[index]  # type: ignore[index]

    def __len__(self):
        if self._length > -1:
            return self._length
        try:
            self._length = len(self.datapipe)
            return self._length
        except (TypeError, NotImplementedError):
            self._length = -1
        if self._map is None:
            warnings.warn(
                "Data from prior DataPipe are loaded to get length of"
                "IterToMapConverter before execution of the pipeline."
                "Please consider removing len()."
            )
            self._load_map()
        self._length = len(self._map)  # type: ignore[arg-type]
        return self._length

    def __getstate__(self):
        self._load_map()
        if DILL_AVAILABLE:
            dill_key_fn = dill.dumps(self.key_fn)
            dill_value_fn = dill.dumps(self.value_fn)
        else:
            dill_key_fn = self.key_fn
            dill_value_fn = self.value_fn
        return (
            self.datapipe,
            dill_key_fn,
            dill_value_fn,
            self._map,
        )

    def __setstate__(self, state):
        (self.datapipe, dill_key_fn, dill_value_fn, self._map) = state
        if DILL_AVAILABLE:
            self.key_fn = dill.loads(dill_key_fn)  # type: ignore[assignment]
            self.value_fn = dill.loads(dill_value_fn)  # type: ignore[assignment]
        else:
            self.key_fn = dill_key_fn  # type: ignore[assignment]
            self.value_fn = dill_value_fn  # type: ignore[assignment]


# Register for functional API
# See Issue https://github.com/pytorch/data/issues/200
IterDataPipe.register_datapipe_as_function("to_map", IterToMapConverterMapDataPipe)
